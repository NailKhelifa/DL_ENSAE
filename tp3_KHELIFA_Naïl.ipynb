{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST with an MLP, from scratch\n",
    "\n",
    "# - Step 1: build an MLP from scratch to solve MNIST. Question set: https://fleuret.org/dlc/materials/dlc-practical-3.pdf\n",
    "# - Step 2: debug your network with backprop ninja and a reference implementation using torch's .backward()\n",
    "# - Step 3: build the same MLP but will full pytorch code (nn.Linear, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6569059a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input[4].view((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (preds, targets):\n",
    "    \"\"\" Computes the accuracy between predictions and targets. Data is expected to be one-hot encoded. \"\"\"\n",
    "    _, idx1 = torch.max(preds, dim=1)\n",
    "    _, idx2 = torch.max(targets, dim=1)\n",
    "    d = idx1 == idx2\n",
    "    return d.int().float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "# this cell should return 0.75\n",
    "preds = torch.zeros((4,7))\n",
    "preds[0,1] = 1\n",
    "preds[1,4] = 1\n",
    "preds[2,2] = 1\n",
    "preds[3,6] = 1\n",
    "targets = torch.zeros((4,7))\n",
    "targets[0,1] = 1\n",
    "targets[1,4] = 1\n",
    "targets[2,2] = 1\n",
    "targets[3,2] = 1\n",
    "compute_accuracy(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def dsigma(x):\n",
    "    return 1 - torch.pow(sigma(x), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss (v,t):\n",
    "    \n",
    "    return torch.sum(torch.pow(v-t, 2))\n",
    "\n",
    "def dloss(v,t):\n",
    "    \n",
    "    return torch.mul(2, (v-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1523,  1.3528, -0.5480, -1.3731, -1.6717, -2.3473],\n",
       "        [ 2.9173,  1.4981, -1.6015, -1.7099,  1.3314,  3.7901],\n",
       "        [-1.9368, -5.4828,  0.0657,  3.2819, -0.0167, -1.5539]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "v = torch.randn((3, 6), dtype=torch.float32)\n",
    "t = torch.randn((3, 6), dtype=torch.float32)\n",
    "l=loss(v,t)\n",
    "dloss(v,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply targets by 0.9 to be in the range of tanh\n",
    "train_target *= 0.9\n",
    "test_target *= 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "# DO NOT MODIFY IT\n",
    "#\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "w1 = torch.randn((784, 50)) \n",
    "b1 = torch.randn((50))\n",
    "w2 = torch.randn((50, 10)) \n",
    "b2 = torch.randn((10))\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/c_69_lv95n33jqfn1l50n0ww0000gn/T/ipykernel_55845/1095281723.py:3: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3641.)\n",
      "  z1 = x1 @ w1 + b1.T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]), tensor(43.2825, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = train_input[:5]\n",
    "y1 = train_target[:5]\n",
    "z1 = x1 @ w1 + b1.T\n",
    "h1 = sigma(z1)\n",
    "z2 = h1 @ w2 + b2.T\n",
    "h2 = sigma(z2)\n",
    "l = loss(h2, y1)\n",
    "h2.shape, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=43.28252410888672\n"
     ]
    }
   ],
   "source": [
    "# Force pytorch to retain grade for intermediate nodes and reset grad for parameters\n",
    "# DO NOT MODIFY THIS CODE\n",
    "#\n",
    "others = [h2,z2,h1,z1]\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in others:\n",
    "    t.retain_grad()\n",
    "l.backward()\n",
    "print(f'loss={l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "z2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "w2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "z1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "w1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# here we compare our gradient to the reference gradient computed by pytorch\n",
    "dl = 1.0\n",
    "dh2 = dloss(h2, y1) * dl\n",
    "cmp('h2',dh2,h2)\n",
    "dz2 = dsigma(z2) * dh2\n",
    "cmp('z2',dz2, z2)\n",
    "dw2 = h1.T @ dz2\n",
    "cmp('w2',dw2, w2)\n",
    "db2 = dz2.sum(axis=0, keepdim=True)\n",
    "cmp('b2',db2, b2)\n",
    "dh1 = dz2 @ w2.T\n",
    "cmp('h1',dh1, h1)\n",
    "dz1 = dsigma(z1) * dh1\n",
    "cmp('z1', dz1, z1)\n",
    "dw1 = x1.T @ dz1\n",
    "cmp('w1', dw1, w1)\n",
    "db1 = dz1.sum(axis=0, keepdim=True)\n",
    "cmp('b1', db1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    w1 += -lr * dw1\n",
    "    b1 += -lr * db1.squeeze()\n",
    "    w2 += -lr * dw2\n",
    "    b2 += -lr * db2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.28252410888672"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = loss(h2, y1)\n",
    "l.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that we've checked our gradients are correct, we can implement the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w1, b1, w2, b2, x1):\n",
    "    z1 = x1 @ w1 + b1.T\n",
    "    h1 = sigma(z1)\n",
    "    z2 = h1 @ w2 + b2.T\n",
    "    h2 = sigma(z2)\n",
    "    return z1, h1, z2, h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(w1, b1, w2, b2, x1, y1, h2, z2, h1, z1):\n",
    "    dl = 1.0\n",
    "    dh2 = dloss(h2, y1) * dl\n",
    "    dz2 = dsigma(z2) * dh2\n",
    "    dw2 = h1.T @ dz2\n",
    "    db2 = dz2.sum(axis=0, keepdim=True)\n",
    "    dh1 = dz2 @ w2.T\n",
    "    dz1 = dsigma(z1) * dh1\n",
    "    dw1 = x1.T @ dz1\n",
    "    db1 = dz1.sum(axis=0, keepdim=True)\n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    with torch.no_grad():\n",
    "        w1 += -lr * dw1\n",
    "        b1 += -lr * db1.squeeze()\n",
    "        w2 += -lr * dw2\n",
    "        b2 += -lr * db2.squeeze()\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \"\"\" init a network \"\"\"\n",
    "    w1 = torch.randn((784, 50), requires_grad=True) \n",
    "    b1 = torch.randn((50), requires_grad=True)\n",
    "    w2 = torch.randn((50, 10), requires_grad=True) \n",
    "    b2 = torch.randn((10), requires_grad=True)\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop\n",
    "torch.set_printoptions(linewidth=200)\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input[:5]\n",
    "        yb = train_target[:5]\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        lsi = loss(h2, yb)\n",
    "        # backward\n",
    "        dw1, db1, dw2, db2 = backward(w1, b1, w2, b2, x1, y1, h2, z2, h1, z1)\n",
    "        # update\n",
    "        lr = 0.1 / num_samples if step < 5000 else 0.01 / num_samples\n",
    "        w1, b1, w2, b2 = update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr)\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 49.75879669189453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 100, loss = 30.87749481201172\n",
      "step = 200, loss = 30.878313064575195\n",
      "step = 300, loss = 30.059812545776367\n",
      "step = 400, loss = 29.930912017822266\n",
      "step = 500, loss = 29.927156448364258\n",
      "step = 600, loss = 29.92056655883789\n",
      "step = 700, loss = 28.314281463623047\n",
      "step = 800, loss = 26.91196060180664\n",
      "step = 900, loss = 27.032424926757812\n",
      "step = 1000, loss = 27.035686492919922\n",
      "step = 1100, loss = 27.035446166992188\n",
      "step = 1200, loss = 27.03508949279785\n",
      "step = 1300, loss = 27.034521102905273\n",
      "step = 1400, loss = 27.032886505126953\n",
      "step = 1500, loss = 26.050735473632812\n",
      "step = 1600, loss = 26.180971145629883\n",
      "step = 1700, loss = 26.18096351623535\n",
      "step = 1800, loss = 26.180912017822266\n",
      "step = 1900, loss = 26.180795669555664\n",
      "step = 2000, loss = 26.181467056274414\n",
      "step = 2100, loss = 26.183025360107422\n",
      "step = 2200, loss = 26.18302345275879\n",
      "step = 2300, loss = 26.182952880859375\n",
      "step = 2400, loss = 26.182886123657227\n",
      "step = 2500, loss = 26.18280792236328\n",
      "step = 2600, loss = 26.18271827697754\n",
      "step = 2700, loss = 26.182607650756836\n",
      "step = 2800, loss = 26.182458877563477\n",
      "step = 2900, loss = 26.18222999572754\n",
      "step = 3000, loss = 26.18178939819336\n",
      "step = 3100, loss = 26.180585861206055\n",
      "step = 3200, loss = 26.177629470825195\n",
      "step = 3300, loss = 26.177282333374023\n",
      "step = 3400, loss = 26.176532745361328\n",
      "step = 3500, loss = 26.17432403564453\n",
      "step = 3600, loss = 25.27475929260254\n",
      "step = 3700, loss = 25.273347854614258\n",
      "step = 3800, loss = 25.271657943725586\n",
      "step = 3900, loss = 25.270273208618164\n",
      "step = 4000, loss = 25.268686294555664\n",
      "step = 4100, loss = 25.266565322875977\n",
      "step = 4200, loss = 25.263397216796875\n",
      "step = 4300, loss = 25.257431030273438\n",
      "step = 4400, loss = 25.10599136352539\n",
      "step = 4500, loss = 24.060178756713867\n",
      "step = 4600, loss = 24.100996017456055\n",
      "step = 4700, loss = 24.03922462463379\n",
      "step = 4800, loss = 24.06527328491211\n",
      "step = 4900, loss = 24.110855102539062\n",
      "step = 5000, loss = 24.03890609741211\n",
      "step = 5100, loss = 19.01968002319336\n",
      "step = 5200, loss = 19.019535064697266\n",
      "step = 5300, loss = 19.01946258544922\n",
      "step = 5400, loss = 19.019432067871094\n",
      "step = 5500, loss = 19.019412994384766\n",
      "step = 5600, loss = 19.0194034576416\n",
      "step = 5700, loss = 19.019397735595703\n",
      "step = 5800, loss = 19.019392013549805\n",
      "step = 5900, loss = 19.019386291503906\n",
      "step = 6000, loss = 19.019380569458008\n",
      "step = 6100, loss = 19.01937484741211\n",
      "step = 6200, loss = 19.01936912536621\n",
      "step = 6300, loss = 19.019365310668945\n",
      "step = 6400, loss = 19.019359588623047\n",
      "step = 6500, loss = 19.019351959228516\n",
      "step = 6600, loss = 19.019344329833984\n",
      "step = 6700, loss = 19.019338607788086\n",
      "step = 6800, loss = 19.019332885742188\n",
      "step = 6900, loss = 19.019325256347656\n",
      "step = 7000, loss = 19.019319534301758\n",
      "step = 7100, loss = 19.019311904907227\n",
      "step = 7200, loss = 19.019306182861328\n",
      "step = 7300, loss = 19.019298553466797\n",
      "step = 7400, loss = 19.019290924072266\n",
      "step = 7500, loss = 19.019283294677734\n",
      "step = 7600, loss = 19.019275665283203\n",
      "step = 7700, loss = 19.019268035888672\n",
      "step = 7800, loss = 19.019258499145508\n",
      "step = 7900, loss = 19.019250869750977\n",
      "step = 8000, loss = 19.019241333007812\n",
      "step = 8100, loss = 19.01923370361328\n",
      "step = 8200, loss = 19.019224166870117\n",
      "step = 8300, loss = 19.019214630126953\n",
      "step = 8400, loss = 19.01920509338379\n",
      "step = 8500, loss = 19.019195556640625\n",
      "step = 8600, loss = 19.019184112548828\n",
      "step = 8700, loss = 19.01917266845703\n",
      "step = 8800, loss = 19.019161224365234\n",
      "step = 8900, loss = 19.01915168762207\n",
      "step = 9000, loss = 19.01913833618164\n",
      "step = 9100, loss = 19.019126892089844\n",
      "step = 9200, loss = 19.01911163330078\n",
      "step = 9300, loss = 19.01909828186035\n",
      "step = 9400, loss = 19.01908302307129\n",
      "step = 9500, loss = 19.01906967163086\n",
      "step = 9600, loss = 19.019054412841797\n",
      "step = 9700, loss = 19.019039154052734\n",
      "step = 9800, loss = 19.01902198791504\n",
      "step = 9900, loss = 19.019006729125977\n",
      "train_accuracy=0.12399999797344208\n",
      "test_accuracy=0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb63023ff70>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reference implementation using pytorch's .backward()\n",
    "Nothing to do in Step 2, this code is provided for you as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import torch.nn as F\n",
    "\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        xloss = F.MSELoss()\n",
    "        lsi = xloss(h2, yb) * yb.nelement()\n",
    "        # backward\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        lsi.backward()\n",
    "        # update\n",
    "        lr = 0.1 / num_samples\n",
    "        for p in parameters:\n",
    "            p.data += -lr * p.grad\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 9688.7314453125\n",
      "step = 100, loss = 8081.2158203125\n",
      "step = 200, loss = 7659.97900390625\n",
      "step = 300, loss = 7363.07666015625\n",
      "step = 400, loss = 7128.52294921875\n",
      "step = 500, loss = 6945.9833984375\n",
      "step = 600, loss = 6739.36767578125\n",
      "step = 700, loss = 6501.99755859375\n",
      "step = 800, loss = 6054.1748046875\n",
      "step = 900, loss = 5933.42529296875\n",
      "step = 1000, loss = 5727.693359375\n",
      "step = 1100, loss = 5324.39453125\n",
      "step = 1200, loss = 5201.4736328125\n",
      "step = 1300, loss = 4857.421875\n",
      "step = 1400, loss = 4587.25\n",
      "step = 1500, loss = 4433.1171875\n",
      "step = 1600, loss = 4352.0341796875\n",
      "step = 1700, loss = 4229.9267578125\n",
      "step = 1800, loss = 3970.349365234375\n",
      "step = 1900, loss = 3771.70263671875\n",
      "step = 2000, loss = 3682.06689453125\n",
      "step = 2100, loss = 3569.414794921875\n",
      "step = 2200, loss = 3367.677001953125\n",
      "step = 2300, loss = 3140.63330078125\n",
      "step = 2400, loss = 3061.024658203125\n",
      "step = 2500, loss = 2966.000244140625\n",
      "step = 2600, loss = 2836.466552734375\n",
      "step = 2700, loss = 2613.8349609375\n",
      "step = 2800, loss = 2100.2998046875\n",
      "step = 2900, loss = 2032.8404541015625\n",
      "step = 3000, loss = 1938.079345703125\n",
      "step = 3100, loss = 1849.05712890625\n",
      "step = 3200, loss = 1761.492431640625\n",
      "step = 3300, loss = 1664.6181640625\n",
      "step = 3400, loss = 1566.6748046875\n",
      "step = 3500, loss = 1458.5361328125\n",
      "step = 3600, loss = 1208.6114501953125\n",
      "step = 3700, loss = 1022.2073364257812\n",
      "step = 3800, loss = 956.7059326171875\n",
      "step = 3900, loss = 884.3306274414062\n",
      "step = 4000, loss = 766.1898193359375\n",
      "step = 4100, loss = 517.1793212890625\n",
      "step = 4200, loss = 463.0394287109375\n",
      "step = 4300, loss = 445.9458923339844\n",
      "step = 4400, loss = 437.5187072753906\n",
      "step = 4500, loss = 432.20843505859375\n",
      "step = 4600, loss = 426.7678527832031\n",
      "step = 4700, loss = 421.21044921875\n",
      "step = 4800, loss = 416.70819091796875\n",
      "step = 4900, loss = 413.31707763671875\n",
      "step = 5000, loss = 410.3262634277344\n",
      "step = 5100, loss = 407.24237060546875\n",
      "step = 5200, loss = 404.2326354980469\n",
      "step = 5300, loss = 401.84271240234375\n",
      "step = 5400, loss = 400.10833740234375\n",
      "step = 5500, loss = 398.65301513671875\n",
      "step = 5600, loss = 397.2428894042969\n",
      "step = 5700, loss = 395.4215393066406\n",
      "step = 5800, loss = 393.1811218261719\n",
      "step = 5900, loss = 390.6314697265625\n",
      "step = 6000, loss = 387.3067626953125\n",
      "step = 6100, loss = 384.9447937011719\n",
      "step = 6200, loss = 383.3662109375\n",
      "step = 6300, loss = 381.9787902832031\n",
      "step = 6400, loss = 380.35943603515625\n",
      "step = 6500, loss = 378.911376953125\n",
      "step = 6600, loss = 377.70343017578125\n",
      "step = 6700, loss = 376.4911804199219\n",
      "step = 6800, loss = 375.2168884277344\n",
      "step = 6900, loss = 373.88763427734375\n",
      "step = 7000, loss = 372.70501708984375\n",
      "step = 7100, loss = 371.6690979003906\n",
      "step = 7200, loss = 370.7222900390625\n",
      "step = 7300, loss = 369.7820739746094\n",
      "step = 7400, loss = 368.7923278808594\n",
      "step = 7500, loss = 367.9155578613281\n",
      "step = 7600, loss = 367.11383056640625\n",
      "step = 7700, loss = 366.3200988769531\n",
      "step = 7800, loss = 365.4836730957031\n",
      "step = 7900, loss = 364.6641845703125\n",
      "step = 8000, loss = 363.91802978515625\n",
      "step = 8100, loss = 363.30377197265625\n",
      "step = 8200, loss = 362.83685302734375\n",
      "step = 8300, loss = 362.4276428222656\n",
      "step = 8400, loss = 361.9638366699219\n",
      "step = 8500, loss = 361.3799743652344\n",
      "step = 8600, loss = 360.7023620605469\n",
      "step = 8700, loss = 359.84893798828125\n",
      "step = 8800, loss = 358.9788513183594\n",
      "step = 8900, loss = 358.1663513183594\n",
      "step = 9000, loss = 357.2345275878906\n",
      "step = 9100, loss = 356.3651123046875\n",
      "step = 9200, loss = 355.70037841796875\n",
      "step = 9300, loss = 355.1726379394531\n",
      "step = 9400, loss = 354.6253356933594\n",
      "step = 9500, loss = 354.0486145019531\n",
      "step = 9600, loss = 353.4962158203125\n",
      "step = 9700, loss = 353.0007629394531\n",
      "step = 9800, loss = 352.5473327636719\n",
      "step = 9900, loss = 352.08843994140625\n",
      "train_accuracy=0.8489999771118164\n",
      "test_accuracy=0.6100000143051147\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb6302a0130>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the same MLP layer but with fully pytorch code (nn.Linear(), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network dimensions\n",
    "n_in = 784\n",
    "n_hidden = 200\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_tr = train_input, train_target\n",
    "X_test, Y_test = test_input, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(n_in, n_hidden), \n",
    "            nn.Tanh(), \n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Tanh() \n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=0.11861\taccuracy (train, test): 0.14400\t0.29200\n",
      "step =   1000\tloss=0.00028\taccuracy (train, test): 1.00000\t0.87400\n",
      "step =   2000\tloss=0.00006\taccuracy (train, test): 1.00000\t0.87500\n",
      "step =   3000\tloss=0.00008\taccuracy (train, test): 1.00000\t0.87700\n",
      "step =   4000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.87600\n",
      "step =   5000\tloss=0.00005\taccuracy (train, test): 1.00000\t0.87600\n",
      "step =   6000\tloss=0.00022\taccuracy (train, test): 1.00000\t0.87500\n",
      "step =   7000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.87900\n",
      "step =   8000\tloss=0.00006\taccuracy (train, test): 1.00000\t0.87900\n",
      "step =   9000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.87700\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise: try to improve accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(n_in, n_hidden), \n",
    "            nn.Tanh(), \n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Tanh() \n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model = MLP2()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=0.14064\taccuracy (train, test): 0.09100\t0.11600\n",
      "step =   1000\tloss=0.00023\taccuracy (train, test): 1.00000\t0.88200\n",
      "step =   2000\tloss=0.00128\taccuracy (train, test): 1.00000\t0.88500\n",
      "step =   3000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.88700\n",
      "step =   4000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.88800\n",
      "step =   5000\tloss=0.00004\taccuracy (train, test): 1.00000\t0.88500\n",
      "step =   6000\tloss=0.00012\taccuracy (train, test): 1.00000\t0.89000\n",
      "step =   7000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.88400\n",
      "step =   8000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.88500\n",
      "step =   9000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.88300\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP_with_Dropout(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(784, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.1), \n",
    "            nn.Linear(50, 10),\n",
    "            nn.Tanh()\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model_with_dropout = MLP_with_Dropout()\n",
    "model = MLP()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=0.12555\taccuracy (train, test): 0.11500\t0.12300\n",
      "step =   1000\tloss=0.02307\taccuracy (train, test): 0.94500\t0.79000\n",
      "step =   2000\tloss=0.01677\taccuracy (train, test): 0.97600\t0.81900\n",
      "step =   3000\tloss=0.01388\taccuracy (train, test): 0.98300\t0.83600\n",
      "step =   4000\tloss=0.01236\taccuracy (train, test): 0.98800\t0.84400\n",
      "step =   5000\tloss=0.01153\taccuracy (train, test): 0.98900\t0.84300\n",
      "step =   6000\tloss=0.01108\taccuracy (train, test): 0.99300\t0.84400\n",
      "step =   7000\tloss=0.01083\taccuracy (train, test): 0.99400\t0.84500\n",
      "step =   8000\tloss=0.01070\taccuracy (train, test): 0.99400\t0.84600\n",
      "step =   9000\tloss=0.01063\taccuracy (train, test): 0.99400\t0.84700\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nail_env)",
   "language": "python",
   "name": "nail_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
